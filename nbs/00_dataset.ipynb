{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset \n",
    "> Functions for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dataset\n",
    "# default_cls_lvl 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Basics\n",
    "\n",
    "In this notebook we are going to define the dataset for our Horse Poo Detector. I do the labeling with [prodi.gy](https://prodi.gy/). From there the data is exported as JSONL [JSON-lines](http://jsonlines.org/). The picture itself is encoded in a base64-URL format. The easiest way is to extract the pictures to a folder and then use the libraries given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import json\n",
    "import nbdev\n",
    "import re\n",
    "import base64\n",
    "import PIL\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import jsonlines\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from io import BytesIO\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_jsonl(file_path):\n",
    "    \"\"\"returns a generator which returns each jsonl line.\n",
    "    \"\"\"\n",
    "    with pathlib.Path(file_path).open('r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            try:  # hack to handle broken jsonl\n",
    "                str_json = json.loads(line)\n",
    "                if str_json['answer'] == 'accept':\n",
    "                    yield str_json\n",
    "            except ValueError:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rj = read_jsonl('test_data/sample.jsonl')\n",
    "data_point = next(rj)\n",
    "assert 'image' in data_point, 'image key expected'\n",
    "assert 'width' in data_point, 'width key expected'\n",
    "assert 'height' in data_point, 'height key expected'\n",
    "assert 'spans' in data_point, 'spans key expected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def base64ToImage(base64_string):\n",
    "    \"\"\" convert base64 string to image\"\"\"\n",
    "    base64_string = base64_string[23:]\n",
    "    imgdata = base64.b64decode(str(base64_string))\n",
    "    image = PIL.Image.open(io.BytesIO(imgdata))\n",
    "    #image = np.rollaxis(np.array(image), 2, 0)\n",
    "    #image = pil2tensor(image,np.float32)\n",
    "    #image.div_(255)\n",
    "    #image = Image(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_padding(image:PIL.Image, target_size=640):\n",
    "    \"\"\"this function adds padding so we have a rectangulare shape\"\"\"\n",
    "    delta_w = target_size - image.size[0]\n",
    "    delta_h = target_size - image.size[1]\n",
    "    padding = (delta_w//2, delta_h//2, delta_w-(delta_w//2), delta_h-(delta_h//2))\n",
    "    new_im = PIL.ImageOps.expand(image, padding)\n",
    "    return new_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rj = read_jsonl('test_data/sample.jsonl')\n",
    "data_point = next(rj)\n",
    "image = base64ToImage(data_point['image'])\n",
    "\n",
    "before = image.size\n",
    "image = add_padding(image)\n",
    "after = image.size\n",
    "assert before != after\n",
    "assert after[0] == after[1]\n",
    "assert before[0] == after[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rj = read_jsonl('test_data/sample.jsonl')\n",
    "data_point = next(rj)\n",
    "image = base64ToImage(data_point['image'])\n",
    "assert type(image) == PIL.JpegImagePlugin.JpegImageFile\n",
    "assert image.size == (640, 352)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def span_to_box(jsonl:str, adjust_for_padding=0):\n",
    "    \"\"\"converts span data to list with points and labels\"\"\"\n",
    "    box_points = []\n",
    "    labels = []\n",
    "    for box in jsonl['spans']:\n",
    "        x1 = np.array(box['points'])[:,1].min() + adjust_for_padding\n",
    "        x2 = np.array(box['points'])[:,1].max() + adjust_for_padding\n",
    "        y1 = np.array(box['points'])[:,0].min()\n",
    "        y2 = np.array(box['points'])[:,0].max()\n",
    "        box_points.append([x1,y1,x2,y2])\n",
    "        labels.append(box['label'])\n",
    "    return [box_points, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rj = read_jsonl('test_data/sample.jsonl')\n",
    "data_point = next(rj)\n",
    "boxes = span_to_box(data_point)\n",
    "\n",
    "assert len(boxes) == 2\n",
    "assert len(boxes[0][0]) == 4\n",
    "assert len(boxes[1]) == 1\n",
    "\n",
    "\n",
    "boxes_with_padding = span_to_box(data_point, adjust_for_padding=100)\n",
    "assert boxes[0][0][0] + 100 == boxes_with_padding[0][0][0]\n",
    "assert boxes[0][0][2] + 100 == boxes_with_padding[0][0][2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def jsonl_convert(path:Path, add_pad=True):\n",
    "    \"\"\"convert jsonl to folder  with image files for better handling\"\"\"\n",
    "    if type(path) == str:\n",
    "        path = Path(path)\n",
    "    path_target_fld = (path.parent / path.stem)\n",
    "    path_target_fld.mkdir(parents=True, exist_ok=True)\n",
    "    boxes = dict()\n",
    "    for jsonl in read_jsonl(str(path)):\n",
    "        base64_string = jsonl['image']\n",
    "        base64_string = base64_string[23:]\n",
    "        imgdata = base64.b64decode(str(base64_string))\n",
    "        image = PIL.Image.open(io.BytesIO(imgdata))\n",
    "        image_size = image.size\n",
    "        if add_pad:\n",
    "            image = add_padding(image)\n",
    "        image.save(str(path_target_fld / jsonl['meta']['file']))\n",
    "\n",
    "        adjustment = (image_size[0] - image_size[1])/2\n",
    "        boxes[jsonl['meta']['file']] = span_to_box(jsonl, adjust_for_padding=adjustment)\n",
    "\n",
    "    with open(path_target_fld / 'boxes.json', 'w') as fp:\n",
    "        json.dump(boxes, fp)\n",
    "\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \n",
    "\n",
    "# delete folder and content\n",
    "import os, shutil\n",
    "\n",
    "\n",
    "folder = 'test_data/sample/'\n",
    "if os.path.isdir(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "\n",
    "    shutil.rmtree(folder)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = jsonl_convert('test_data/sample.jsonl')\n",
    "\n",
    "assert os.path.isfile(str(Path(folder) / '20190607060607_784617.jpg'))\n",
    "assert len(os.listdir(folder)) == 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def get_labels_for_folder(folder:Path):\n",
    "    \"\"\"reads labels from boxes.json file\"\"\"\n",
    "    if type(folder) is str:\n",
    "        folder = Path(folder)\n",
    "    with open(str(folder / 'boxes.json'), 'r') as fp:\n",
    "        data = json.load(fp)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Path('test_data/sample')\n",
    "file = Path('test_data/sample.jsonl')\n",
    "jsonl_convert(file)\n",
    "boxes = get_labels_for_folder(folder)\n",
    "\n",
    "assert len(boxes) == 4\n",
    "assert '20190607060607_784617.jpg' in boxes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'test_data/sample/' \n",
    "boxes = get_labels_for_folder(folder)\n",
    "transforms = [[flip_lr(p=0.5), brightness(change=(0.4, 0.6), p=0.75), contrast(scale=(0.8, 1.25), p=.75)],[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (ObjectItemList\n",
    "        .from_folder(folder)\n",
    "        .split_by_rand_pct(0.5)\n",
    "        .label_from_func(lambda o: boxes[o.name])\n",
    "        .transform(transforms, tfm_y=True)\n",
    "        .databunch(bs=2, collate_fn=bb_pad_collate)\n",
    "       # .normalize(imagenet_stats)\n",
    "       )\n",
    "\n",
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## folder operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def pad_images_in_folder(path:Path, num_start=None, num_of_files=None):\n",
    "    \"\"\"all immages in the folder will be overwritten with images with padding\"\"\"\n",
    "    iterator = path.iterdir()\n",
    "    if num_start is None:\n",
    "        num_start = 0\n",
    "    \n",
    "    if num_of_files is None:\n",
    "        num_of_files = len([f for f in os.listdir(str(path)) if os.path.isfile(os.path.join(path, f))])\n",
    "        num_of_files -= num_start\n",
    "        \n",
    "    stop = num_start + num_of_files\n",
    "    \n",
    "    for i in progress_bar(range(num_of_files)):\n",
    "        if num_start is not None:\n",
    "            if i < num_start:\n",
    "                next(iterator)\n",
    "                continue\n",
    "            if i > stop:\n",
    "                break                \n",
    "        \n",
    "                \n",
    "        path_img = next(iterator)\n",
    "        if path_img.suffix == '.jpg':\n",
    "            print(path_img)\n",
    "            img = PIL.Image.open(str(path_img))            \n",
    "            img = add_padding(img, target_size=640)              \n",
    "            img.save(str(path_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sample data\n",
    "from shutil import copyfile, rmtree\n",
    "\n",
    "\n",
    "\n",
    "path_dest = Path('test_data/pad_samples/padded')\n",
    "path_dest.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "path_source = Path('test_data/pad_samples')\n",
    "\n",
    "for path_src in path_source.iterdir():\n",
    "    if path_src.suffix == '.jpg':\n",
    "        print(f'copy from {path_src} to {path_dest / path_src.name}')\n",
    "        copyfile(path_src, path_dest / path_src.name)\n",
    "\n",
    "pad_images_in_folder(path_dest, num_start=None, num_of_files=None)\n",
    "\n",
    "\n",
    "# run test\n",
    "for path in path_dest.iterdir():\n",
    "    if path.suffix == '.jpg':        \n",
    "        image = PIL.Image.open(path)\n",
    "        image = np.asarray(image)\n",
    "        assert image.shape == (640,640,3), print(f'file {path} not padded with shape {image.shape} ')   \n",
    "        \n",
    "        \n",
    "# clean up \n",
    "import os, shutil\n",
    "folder = str(path_dest)\n",
    "for filename in os.listdir(folder):\n",
    "    file_path = os.path.join(folder, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to delete %s. Reason: %s' % (file_path, e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
