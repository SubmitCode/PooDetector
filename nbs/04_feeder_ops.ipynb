{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp feeder_ops\n",
    "# default_cls_lvl 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feeder Ops\n",
    "\n",
    "> Functions for controlling the feeding machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import argparse\n",
    "from datetime import datetime, timedelta, date\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import paramiko\n",
    "import yagmail\n",
    "from pathlib import Path\n",
    "from logging.handlers import RotatingFileHandler\n",
    "from dotenv import load_dotenv\n",
    "from fastai.vision import *\n",
    "from fastscript import *\n",
    "from astral import LocationInfo\n",
    "from astral.sun import sun\n",
    "from dateutil import tz\n",
    "\n",
    "from influxdb_client import InfluxDBClient, Point, WritePrecision\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "\n",
    "CAP_URL = os.getenv('CAP_URL', default='.')\n",
    "PATH_SAVE_FILES = os.getenv('PATH_SAVE_FILES', default='data')\n",
    "PATH_FILE_LOG = os.getenv('PATH_FILE_LOG', default='data/camera_log')\n",
    "SLEEP_TIME_BETWEEN_CAPTURE = float(os.getenv('SLEEP_TIME_BETWEEN_CAPTURE', default=0.25))\n",
    "\n",
    "\n",
    "ACTIVATE_PREDICTION = bool(os.getenv('ACTIVATE_PREDICTION', default=False))\n",
    "SLEEP_BETWEEN_FEEDING = int(os.getenv('SLEEP_BETWEEN_FEEDING', default=3600))\n",
    "PREDICTION_THRES = float(os.getenv('PREDICTION_THRES', default=0.75))\n",
    "MAX_FEEDING_SESSIONS_PER_DAY = int(os.getenv('MAX_FEEDING_SESSIONS_PER_DAY', default=4))\n",
    "ACTIVATE_FEEDER = bool(os.getenv('ACTIVATE_FEEDER', default=False))\n",
    "PATH_MODEL = os.getenv('PATH_MODEL', default='data')\n",
    "PATH_FOLDER_SUCCESSFUL_PREDICTIONS = os.getenv('PATH_FOLDER_SUCCESSFUL_PREDICTIONS', default='data/successful')\n",
    "\n",
    "FEEDER_URL = os.getenv('FEEDER_URL')\n",
    "FEEDER_USER = os.getenv('FEEDER_USER')\n",
    "FEEDER_PWD = os.getenv('FEEDER_PWD')\n",
    "FEEDER_CMD = os.getenv('FEEDER_CMD', default='echo test')\n",
    "\n",
    "\n",
    "INFLUX_TOKEN=os.getenv('INFLUX_TOKEN')\n",
    "INFLUX_ORG=os.getenv('INFLUX_ORG')\n",
    "INFLUX_BUCKET=os.getenv('INFLUX_BUCKET')\n",
    "INFLUX_URL=os.getenv('INFLUX_URL')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TlsSMTPHandler(logging.handlers.SMTPHandler):\n",
    "    def emit(self, record):\n",
    "        \"\"\"\n",
    "        Emit a record.\n",
    " \n",
    "        Format the record and send it to the specified addressees.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            \n",
    "            msg = self.format(record)\n",
    "            mail = yagmail.SMTP(\"wilhelm.fritsche@gmail.com\")\n",
    "            mail.send(\n",
    "                subject=\"Poodetector Error\", \n",
    "                to=[\"wilhelm.fritsche@gmail.com\"], \n",
    "                contents=msg)\n",
    "        except (KeyboardInterrupt, SystemExit):\n",
    "            raise\n",
    "        except:\n",
    "            self.handleError(record)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_test = logging.getLogger(\"test\")\n",
    "log_test.handlers = []\n",
    "mail_handler = TlsSMTPHandler((\"smtp.gmail.com\", 587), 'bugs@my_company.com', ['admin@my_company.com'], 'Error found!', ('my_company_account@gmail.com', 'top_secret_gmail_password'))\n",
    "mail_handler.setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "formatter = logging.Formatter(\n",
    "        fmt='%(asctime)s p%(process)s {%(pathname)s:%(lineno)d} %(levelname)s - %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S')\n",
    "mail_handler.setFormatter(formatter)\n",
    "log_test.addHandler(mail_handler)\n",
    "\n",
    "\n",
    "log_test.error(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_logger(log_file=None):\n",
    "    \"\"\"\n",
    "    Initialize global logger and return it.\n",
    "\n",
    "    :param log_file: log to this file, or to standard output if None\n",
    "    :return: created logger\n",
    "    \"\"\"\n",
    "        \n",
    "    formatter = logging.Formatter(\n",
    "        fmt='%(asctime)s p%(process)s {%(pathname)s:%(lineno)d} %(levelname)s - %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    log = logging.getLogger()\n",
    "    if len(log.handlers) >= 2:\n",
    "        return log\n",
    "        \n",
    "    log.setLevel(logging.INFO)\n",
    "    if log_file is not None:\n",
    "        os.makedirs(os.path.dirname(log_file), exist_ok=True)\n",
    "        handler = RotatingFileHandler(\n",
    "            log_file,\n",
    "            maxBytes=1024*1024*30,\n",
    "            backupCount=3)\n",
    "        handler.setFormatter(formatter)\n",
    "        log.addHandler(handler)\n",
    "        handler.setLevel(logging.DEBUG)\n",
    "\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(formatter)\n",
    "    handler.setLevel(logging.INFO)\n",
    "    log.addHandler(handler)\n",
    "    \n",
    "    mail_handler = TlsSMTPHandler((\"...\", 587), '...', ['...'], '.', ('...', '...'))\n",
    "    mail_handler.setLevel(logging.ERROR)\n",
    "    mail_handler.setFormatter(formatter)\n",
    "    log.addHandler(mail_handler)\n",
    "    \n",
    "\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_folder(path: Path, foldername):\n",
    "    \"\"\" creates a folder if it does not exist already \"\"\"\n",
    "    (path / foldername).mkdir(parents=True, exist_ok=True)\n",
    "    return path / foldername"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_testing\n",
    "model = load_learner(PATH_MODEL)\n",
    "#model.predict(open_image('data/horse_poo/20181215091846-poo_day.jpg'))[2][0].numpy() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_sunrise():\n",
    "    \"\"\"gets the sunrise as an int\"\"\"\n",
    "    city = LocationInfo(\"Ludesch\", \"Austria\", \"Europe/Berlin\", 47.2, 9.7)\n",
    "    s = sun(city.observer, date= datetime.now())\n",
    "    return int(s[\"sunrise\"].astimezone(tz.tzlocal()).strftime('%H%M'))\n",
    "\n",
    "\n",
    "def get_sunset():\n",
    "    \"\"\"gets the sunset as an int\"\"\"\n",
    "    city = LocationInfo(\"Ludesch\", \"Austria\", \"Europe/Berlin\", 47.2, 9.7)\n",
    "    s = sun(city.observer, date= datetime.now())\n",
    "    return int(s[\"sunset\"].astimezone(tz.tzlocal()).strftime('%H%M'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sunrise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "def send_mail_with_pic(image:[str,Path]):\n",
    "    \"\"\"send a mail with an embedded picture\"\"\"\n",
    "    image = Path(image)\n",
    "    mail = yagmail.SMTP(\"wilhelm.fritsche@gmail.com\")\n",
    "    mail.send(\n",
    "        subject=\"running feeder\", \n",
    "        to=[\"wilhelm.fritsche@gmail.com\", \n",
    "            \"pernerwuerstel@gmail.com\"], \n",
    "        contents=yagmail.inline(str(image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_testing\n",
    "path = Path('test_data/no_horse_poo/20181215105642-poo_day.jpg')\n",
    "if path.exists():\n",
    "    send_mail_with_pic(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def run_feeder():\n",
    "    \"\"\"runs feeder\"\"\"\n",
    "    logger = logging.getLogger()   \n",
    "    ssh = paramiko.SSHClient()\n",
    "    ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "    ssh.connect(FEEDER_URL, username=FEEDER_USER, password=FEEDER_PWD)\n",
    "    ssh_stdin, ssh_stdout, ssh_stder = ssh.exec_command(FEEDER_CMD)\n",
    "    logger.info(ssh_stdout.read())\n",
    "    logger.info(ssh_stder.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_testing\n",
    "run_feeder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influx setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```docker run -v $PWD:/var/lib/influxdb --name influxdb -d -p 8086:8086 quay.io/influxdb/influxdb:v2.0.3```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_influx_api():\n",
    "    \"\"\"returns influx write_api\"\"\"\n",
    "    if INFLUX_URL is None:\n",
    "        return None\n",
    "    \n",
    "    client = InfluxDBClient(url=INFLUX_URL, token=INFLUX_TOKEN)\n",
    "    write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "    return write_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_testing\n",
    "write_api = get_influx_api()\n",
    "write_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def write_to_influx(path:Path, accuracy, write_api):\n",
    "    \"\"\"write datapoint to influx\"\"\"\n",
    "    if INFLUX_BUCKET is not None:\n",
    "        point = Point(\"ai\")\\\n",
    "            .tag(\"filename\", path.name)\\\n",
    "            .tag(\"path\", str(path))\\\n",
    "            .field(\"accuracy\", float(accuracy))\\\n",
    "            .time(datetime.utcnow(), WritePrecision.NS)\n",
    "        write_api.write(INFLUX_BUCKET, INFLUX_ORG, point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_testing\n",
    "write_to_influx(Path(\"/home/test.jpg\"), 0.938, write_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@call_parse\n",
    "def cap_and_predict():\n",
    "    \"\"\"this function captures camera pictures. To configure this function please use a .env file\"\"\"   \n",
    "    \n",
    "        \n",
    "    logger = get_logger(PATH_FILE_LOG)\n",
    "\n",
    "    path = Path(PATH_SAVE_FILES)    \n",
    "    \n",
    "    current_date = datetime.today().date()\n",
    "    prev_date = datetime.min.date    \n",
    "    last_cap_time = datetime.min\n",
    "    \n",
    "    last_run_feeder = datetime.min\n",
    "    num_run_feeder_per_day = 0\n",
    "    \n",
    "    write_api = get_influx_api()\n",
    "    \n",
    "    model = None\n",
    "    if ACTIVATE_PREDICTION:\n",
    "        model = load_learner(PATH_MODEL)\n",
    "    \n",
    "    while True:\n",
    "        time.sleep(10)\n",
    "        logger.info('outer while loop')\n",
    "\n",
    "        try:\n",
    "            cap = cv2.VideoCapture(CAP_URL)\n",
    "            cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "            while cap.isOpened():\n",
    "                \n",
    "                ret, pic = cap.read()\n",
    "                \n",
    "                if ret is False:\n",
    "                    logger.warning('pic not readable')\n",
    "                    break\n",
    "\n",
    "                now = datetime.now()\n",
    "                current_date = datetime.today().date()                \n",
    "                time_current = int(now.strftime('%H%M'))\n",
    "                \n",
    "                if get_sunrise() > time_current:\n",
    "                    continue\n",
    "\n",
    "                if get_sunset() < time_current:\n",
    "                    continue\n",
    "\n",
    "                if prev_date != current_date:\n",
    "                    num_run_feeder_per_day = 0                    \n",
    "                    fld_save_to = create_folder(path, current_date.strftime('%Y%m%d'))\n",
    "                    # reload model\n",
    "                    if ACTIVATE_PREDICTION:\n",
    "                        model = load_learner(PATH_MODEL)\n",
    "                    logger.info(f\"msg=update folder to {current_date}\")\n",
    "                \n",
    "                now_str = now.strftime('%Y%m%d%H%M%S_%f')\n",
    "                path_save_file = fld_save_to / (now_str + '.jpg')\n",
    "                \n",
    "                cv2.imwrite(str(path_save_file), pic)\n",
    "                    \n",
    "                prev_date = datetime.today().date() #assign new date to compare to\n",
    "                \n",
    "                prediction = None\n",
    "                if ACTIVATE_PREDICTION:\n",
    "                    img = open_image(path_save_file)\n",
    "                    prediction = model.predict(img)[2][0].numpy()\n",
    "                    folder =  Path(PATH_FOLDER_SUCCESSFUL_PREDICTIONS) / current_date.strftime('%Y%m%d')\n",
    "                    \n",
    "                    #influx\n",
    "                    write_to_influx(path_save_file, prediction, write_api)\n",
    "                    \n",
    "                    \n",
    "                    if prediction >= PREDICTION_THRES:\n",
    "                        logger.info('successful prediction')\n",
    "                        folder = create_folder(Path(PATH_FOLDER_SUCCESSFUL_PREDICTIONS), \n",
    "                                               current_date.strftime('%Y%m%d'))\n",
    "                        img.save(folder / path_save_file.name) #save also  in a special folder\n",
    "                    elif last_cap_time >= datetime.now() or float(prediction) < 0.1:\n",
    "                        path_save_file.unlink()\n",
    "                    else:\n",
    "                        last_cap_time = datetime.now() + timedelta(seconds=SLEEP_TIME_BETWEEN_CAPTURE)\n",
    "                        \n",
    "                        \n",
    "                \n",
    "                if ACTIVATE_FEEDER and ACTIVATE_PREDICTION:\n",
    "                    if PREDICTION_THRES <= prediction:\n",
    "                        if (last_run_feeder + timedelta(seconds=SLEEP_BETWEEN_FEEDING) < datetime.now() \n",
    "                            and num_run_feeder_per_day <= MAX_FEEDING_SESSIONS_PER_DAY):\n",
    "                            \n",
    "                            last_run_feeder = datetime.now()\n",
    "                            num_run_feeder_per_day += 1\n",
    "                            logger.info(f\"running feeder last_run_feeder=\" +\n",
    "                                        f\"{last_run_feeder} \" +\n",
    "                                        f\"num_run_feeder_per_day={num_run_feeder_per_day} \" + \n",
    "                                        f\"SLEEP_BETWEEN_FEEDING={SLEEP_BETWEEN_FEEDING} \" + \n",
    "                                        f\"MAX_FEEDING_SESSIONS_PER_DAY={MAX_FEEDING_SESSIONS_PER_DAY}\")   \n",
    "                            path_image = folder / path_save_file.name\n",
    "                            send_mail_with_pic(path_image)\n",
    "                            run_feeder()\n",
    "                #time.sleep(SLEEP_TIME_BETWEEN_CAPTURE)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(e)\n",
    "\n",
    "        finally:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_testing\n",
    "from nbdev.export import *\n",
    "notebook2script('04_feeder_ops.ipynb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}