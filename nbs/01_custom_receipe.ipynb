{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prodigy Recipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp custom_recipe\n",
    "# default_cls_lvl 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import copy\n",
    "import io\n",
    "import torch\n",
    "import os\n",
    "import fastai\n",
    "from PIL import Image\n",
    "import PIL\n",
    "from time import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from prodigy.components.loaders import get_stream, JSONL\n",
    "from prodigy.components.preprocess import fetch_images\n",
    "from prodigy.core import recipe, recipe_args\n",
    "from prodigy.util import log, b64_uri_to_bytes, split_string, read_image_b64, write_jsonl, read_jsonl\n",
    "from prodigy.components.loaders import Images\n",
    "from prodigy.components.sorters import prefer_uncertain, prefer_high_scores, prefer_low_scores\n",
    "from prodigy.components.loaders import JSONL\n",
    "import prodigy\n",
    "\n",
    "\n",
    "from fastai.vision import *\n",
    "from pathlib import Path\n",
    "from fastscript import *\n",
    "\n",
    "from datetime import datetime\n",
    "from influxdb_client import InfluxDBClient, Point, WritePrecision\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFLUX_TOKEN=os.getenv('INFLUX_TOKEN')\n",
    "INFLUX_ORG=os.getenv('INFLUX_ORG')\n",
    "INFLUX_BUCKET=os.getenv('INFLUX_BUCKET')\n",
    "INFLUX_URL=os.getenv('INFLUX_URL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fastaimodel recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@recipe(\n",
    "    \"fastaimodel\",\n",
    "    dataset=(\"The dataset to use\", \"positional\", None, str),\n",
    "    source=(\"Path to a directory of images\", \"option\", \"source\", str),\n",
    "    model_path=(\"Path to the fastai model\", \"option\", \"model\", str),\n",
    "    target_folder=(\"Path to the target folder where the pictures are \" +\n",
    "                   \"in the labled folders\", \n",
    "                   \"option\", \n",
    "                   \"target_folder\", \n",
    "                   str),\n",
    "    sort_by_score_type=(\"choose which order you want to receive the predictions. \" +\n",
    "                        \"The availiable orders are prefer_uncertain, prefer_high_scores, prefer_low_scores.\", \n",
    "                        \"option\", \n",
    "                        \"sort\", \n",
    "                        str),\n",
    "    label=(\"One or more comma-separated labels\", \"option\", \"label\", str)    \n",
    ")\n",
    "def fastai_recipe(dataset, source, model_path, target_folder, sort_by_score_type, label='horse_poo'):\n",
    "    \"\"\"recipe to load data in a certain order and save them to a folder\"\"\"\n",
    "\n",
    "    \n",
    "    def update(examples):\n",
    "        # This function is triggered when Prodigy receives annotations\n",
    "        print(f\"type of examples = {type(examples)}\")\n",
    "        for example in examples:\n",
    "            if example['answer'] == 'accept':\n",
    "                save_base64_image(str(target_folder_pos), example['text'] + '.jpg', example['image'])\n",
    "            if example['answer'] == 'reject':\n",
    "                save_base64_image(str(target_folder_neg), example['text'] + '.jpg', example['image'])\n",
    "                    \n",
    "            \n",
    "        #print(f\"Received {len(examples)} annotations!\")\n",
    "      \n",
    "    \n",
    "    #create folders\n",
    "    create_folders(target_folder, label)\n",
    "    target_folder = Path(target_folder)\n",
    "    target_folder_pos = target_folder / label\n",
    "    target_folder_neg = target_folder / ('no_' + label)\n",
    "            \n",
    "    learn = load_fastai_model(model_path)\n",
    "    stream = score_stream(Images(source), model_path)\n",
    "    \n",
    "  \n",
    "    if sort_by_score_type == 'prefer_high_scores':\n",
    "        stream = prefer_high_scores(stream)\n",
    "    elif sort_by_score_type == 'prefer_low_scores':\n",
    "        stream = prefer_low_scores(stream)\n",
    "    elif sort_by_score_type == 'prefer_uncertain':\n",
    "        stream = prefer_uncertain(stream)\n",
    "    \n",
    "    stream.first_n = 20000\n",
    "    \n",
    "\n",
    "    return {\n",
    "        \"dataset\": dataset,\n",
    "        \"view_id\": \"image_manual\",\n",
    "        \"stream\": stream,\n",
    "        \"update\": update,\n",
    "        \"config\": {  # Additional config settings, mostly for app UI\n",
    "            \"label\": \"horse_poo\"\n",
    "        }\n",
    "        \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def create_folders(path:str, label:str) -> None:\n",
    "    \"\"\"create the target folder\"\"\"\n",
    "    path = Path(path)\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    path_pos = path / label\n",
    "    path_pos.mkdir(parents=True, exist_ok=True)\n",
    "    path_neg = path / ('no_' + label)\n",
    "    path_neg.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if folder do not exist\n",
    "if os.path.exists('horse_poo'): Path('horse_poo').rmdir()\n",
    "if os.path.exists('no_horse_poo'): Path('no_horse_poo').rmdir()\n",
    "create_folders('.', 'horse_poo')\n",
    "assert Path('horse_poo').exists() is True\n",
    "assert Path('no_horse_poo').exists() is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_fastai_model(path, test_folder:[Path, str]=None):\n",
    "    \"\"\"load a fastai model from a given path\"\"\"\n",
    "    path = Path(path)\n",
    "    folder = path.parent\n",
    "    file = path.name\n",
    "    if test_folder is not None:\n",
    "        il = ImageList.from_folder(test_folder)\n",
    "        return load_learner(path=folder, file=file, test=il)\n",
    "    return load_learner(str(folder), str(file))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('data/export.pkl'):\n",
    "    model = load_fastai_model('data/export.pkl')\n",
    "    if os.path.exists('test_data/sample/20181216093008.jpg'):\n",
    "        prediction = model.predict(fastai.vision.open_image('test_data/sample/20181216093008.jpg'))        \n",
    "        assert type(model) == fastai.basic_train.Learner\n",
    "     \n",
    "    model = load_fastai_model('data/export.pkl', 'test_data/sample')\n",
    "    preds = model.get_preds(ds_type=DatasetType.Test)\n",
    "    assert type(preds) == list\n",
    "    assert len(preds) == 2\n",
    "    assert preds[0][0,:].shape == torch.Size([2])\n",
    "        \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def save_base64_image(path, filename, uri):\n",
    "    \"\"\"save base64 encoded image \"\"\"\n",
    "    tgt_path = Path(path) / filename\n",
    "    pil_image = PIL.Image.open(io.BytesIO(b64_uri_to_bytes(uri)))\n",
    "    pil_image.save(str(tgt_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def score_stream(stream, model_path):\n",
    "    learn = load_fastai_model(model_path)\n",
    "    for example in stream:\n",
    "        if not example[\"image\"].startswith(\"data\"):\n",
    "            msg = \"Expected base64-encoded data URI, but got: '{}'.\"\n",
    "            raise ValueError(msg.format(example[\"image\"][:100]))\n",
    "\n",
    "        pil_image = PIL.Image.open(io.BytesIO(b64_uri_to_bytes(example[\"image\"])))\n",
    "        a = np.asarray(pil_image)\n",
    "        a = np.transpose(a, (1, 0, 2))\n",
    "        a = np.transpose(a, (2, 1, 0))\n",
    "        x = torch.from_numpy(a.astype(np.float32, copy=False) )\n",
    "        x = x.div_(255)\n",
    "        score = learn.predict(Image(x))[2][0].numpy().item() \n",
    "        print(f\"socre={score}, id={example['text']}\")\n",
    "        yield (score, example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fastai_jsonl_recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def predict_folder(image_folder:[str, Path], path_model:[str, Path]=Path('data/export.pkl')):\n",
    "    \"\"\"predicts a folder of images and saves images in tasks.jsonl\"\"\"\n",
    "    image_folder = Path(image_folder)\n",
    "    path_model = Path(path_model)\n",
    "    learn = load_fastai_model(str(path_model), test_folder=str(image_folder))\n",
    "    preds,y = learn.get_preds(ds_type=DatasetType.Test)\n",
    "    scores = preds[:,learn.data.classes.index('horse_poo')].numpy()\n",
    "    paths = learn.data.test_ds.items\n",
    "    \n",
    "    jsonl_list = []\n",
    "    for score, path in sorted(zip(scores, paths), reverse=True):\n",
    "            obj = {\"image\": str(path), \"text\": path.stem, \"score\": str(np.round(score, 3))}\n",
    "            jsonl_list.append(obj)\n",
    "        \n",
    "    print(f\"save results to {str(image_folder / 'tasks.jsonl')}\")\n",
    "    write_jsonl(str(image_folder / 'tasks.jsonl'), jsonl_list)\n",
    "    \n",
    "    \n",
    "    return learn, preds, y, jsonl_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('data/export.pkl'):\n",
    "    predict_folder(image_folder=Path('test_data/sample/'), path_model='data/export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@call_parse\n",
    "def predict_all_subfolders(path:Param(\"path of parent folder\", str)='data', \n",
    "                           skipXmostRecent:Param(\"skips the nth most recent folders\", int)=1,\n",
    "                           path_model:Param(\"path to the model to use\", str)='data/export.pkl',\n",
    "                           predict_single_folder:Param(\"path to single folder\", str)=None):\n",
    "    \"\"\"predicts all images in subfolders of the given path an creates a tasks.jsonl file\"\"\"\n",
    "    path = Path(path)\n",
    "    \n",
    "    if predict_single_folder is not None:\n",
    "        predict_folder(Path(predict_single_folder), path_model)\n",
    "        return \n",
    "    \n",
    "    subfolders = sorted(next(os.walk(str(path)))[1], reverse=True)\n",
    "    \n",
    "    subfolders = [path / folder for folder in subfolders]\n",
    "    \n",
    "    for folder in subfolders[skipXmostRecent:]:\n",
    "        print(f'predict {folder}')\n",
    "        predict_folder(folder, path_model)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@recipe(\n",
    "    \"fastai_jsonl_recipe\",\n",
    "    dataset=(\"The dataset to use\", \"positional\", None, str),\n",
    "    path_image_folder=(\"folder with tasks.jsonl file\", \"option\", \"path_image_folder\", str),\n",
    "    path_model=(\"folder where we can find the deployed model\", \"option\", \"path_model\", str),\n",
    "    predict=(\"wether to predict if there is already a tasks.jsonl or not\", \"option\", \"predict\", int)\n",
    ")\n",
    "def fastai_jsonl_recipe(dataset, path_image_folder, path_model, predict=0):\n",
    "    \"\"\"recipe to predict and laod data in a certain order\"\"\"\n",
    "    \n",
    "    \n",
    "    def on_load(controller):\n",
    "        \"\"\"crates tasks.jsonl file order by predictions\"\"\"        \n",
    "        if predict == 1 or os.path.exists(path_image_folder) is False:\n",
    "            print(f'make predictions for folder {path_image_folder} and model {path_model}')\n",
    "            predict_folder(image_folder=Path(path_image_folder), path_model=Path(path_model))\n",
    "\n",
    "    source = Path(path_image_folder)\n",
    "    stream = JSONL(str(source / 'tasks.jsonl'))\n",
    "    stream = fetch_images(stream, skip=True)\n",
    "    \n",
    "    return {\n",
    "        \"dataset\": dataset,\n",
    "        \"view_id\": \"image_manual\",\n",
    "        \"on_load\": on_load,\n",
    "        \"stream\": stream,\n",
    "        \"config\": {  # Additional config settings, mostly for app UI\n",
    "            \"label\": \"horse_poo\"\n",
    "        }\n",
    "        \n",
    "    }\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('data/export.pkl'):\n",
    "    res = fastai_jsonl_recipe('test', 'test_data/sample', 'data/export.pkl', 1)\n",
    "    res['on_load']('controller')\n",
    "    assert os.path.exists('test_data/sample/tasks.jsonl')\n",
    "    os.unlink('test_data/sample/tasks.jsonl')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script('01_custom_receipe.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!prodigy fastai_jsonl_recipe binary_horse_poo \\\n",
    "-path_image_folder /mnt/Data/to_label/20210107/ \\\n",
    "-path_model /home/wilhelm/PooDetector/data/tmp/export.pkl \\\n",
    "-predict 0co \\\n",
    "-F /home/wilhelm/PooDetector/PooDetector/custom_recipe.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python PooDetector/custom_recipe.py \\\n",
    "--path /mnt/Data/to_label/ \\\n",
    "--path_model /home/wilhelm/PooDetector/data/tmp/export.pkl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_to_label_jsonl(path_target:[str,Path]=Path('tasks.jsonl'), flux_query:str=None):\n",
    "    \"\"\"creates a jsonl file for the predictions selcted by the flux query\"\"\"\n",
    "    \n",
    "    if flux_query is None:\n",
    "        flux_query = '''\n",
    "            from(bucket: \"poo_detector\")\n",
    "            |> range(start: -48h)\n",
    "            |> filter(fn: (r) => r[\"_measurement\"] == \"ai\")\n",
    "            |> filter(fn: (r) => r[\"_value\"] >= 0.3)            \n",
    "            '''\n",
    "\n",
    "    client = InfluxDBClient(url=INFLUX_URL, token=INFLUX_TOKEN)\n",
    "    df = client.query_api().query_data_frame(query, org=org)\n",
    "\n",
    "    filenames = df.filename.to_list()\n",
    "    paths = df.path.to_list()\n",
    "    scores = df._value.to_list()\n",
    "\n",
    "    jsonl_list = []\n",
    "    for score, path, filename in sorted(zip(scores, paths, filenames), reverse=True):\n",
    "        obj = {\"image\": path, \"text\": filename, \"score\": str(round(score, 3))}\n",
    "        jsonl_list.append(obj)\n",
    "\n",
    "    print(f\"save results to {str(path_target)}\")\n",
    "    write_jsonl(str(path_target), jsonl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_to_label_jsonl()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!prodigy image.manual binary_horse_poo ./tasks.jsonl --loader jsonl --label horse_poo\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
