# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/01_custom_receipe.ipynb (unless otherwise specified).

__all__ = ['fastai_recipe', 'create_folders', 'load_fastai_model', 'save_base64_image', 'score_stream',
           'predict_folder', 'predict_all_subfolders', 'fastai_jsonl_recipe']

# Cell
import numpy as np
import copy
import io
import torch
import os
import fastai
from PIL import Image
import PIL
from time import time
import json
from pathlib import Path

from prodigy.components.loaders import get_stream, JSONL
from prodigy.components.preprocess import fetch_images
from prodigy.core import recipe, recipe_args
from prodigy.util import log, b64_uri_to_bytes, split_string, read_image_b64, write_jsonl, read_jsonl
from prodigy.components.loaders import Images
from prodigy.components.sorters import prefer_uncertain, prefer_high_scores, prefer_low_scores
from prodigy.components.loaders import JSONL
import prodigy


from fastai.vision import *
from pathlib import Path
from fastscript import *

# Cell
@recipe(
    "fastaimodel",
    dataset=("The dataset to use", "positional", None, str),
    source=("Path to a directory of images", "option", "source", str),
    model_path=("Path to the fastai model", "option", "model", str),
    target_folder=("Path to the target folder where the pictures are " +
                   "in the labled folders",
                   "option",
                   "target_folder",
                   str),
    sort_by_score_type=("choose which order you want to receive the predictions. " +
                        "The availiable orders are prefer_uncertain, prefer_high_scores, prefer_low_scores.",
                        "option",
                        "sort",
                        str),
    label=("One or more comma-separated labels", "option", "label", str)
)
def fastai_recipe(dataset, source, model_path, target_folder, sort_by_score_type, label='horse_poo'):
    """recipe to load data in a certain order and save them to a folder"""


    def update(examples):
        # This function is triggered when Prodigy receives annotations
        print(f"type of examples = {type(examples)}")
        for example in examples:
            if example['answer'] == 'accept':
                save_base64_image(str(target_folder_pos), example['text'] + '.jpg', example['image'])
            if example['answer'] == 'reject':
                save_base64_image(str(target_folder_neg), example['text'] + '.jpg', example['image'])


        #print(f"Received {len(examples)} annotations!")


    #create folders
    create_folders(target_folder, label)
    target_folder = Path(target_folder)
    target_folder_pos = target_folder / label
    target_folder_neg = target_folder / ('no_' + label)

    learn = load_fastai_model(model_path)
    stream = score_stream(Images(source), model_path)


    if sort_by_score_type == 'prefer_high_scores':
        stream = prefer_high_scores(stream)
    elif sort_by_score_type == 'prefer_low_scores':
        stream = prefer_low_scores(stream)
    elif sort_by_score_type == 'prefer_uncertain':
        stream = prefer_uncertain(stream)

    stream.first_n = 20000


    return {
        "dataset": dataset,
        "view_id": "image_manual",
        "stream": stream,
        "update": update,
        "config": {  # Additional config settings, mostly for app UI
            "label": "horse_poo"
        }

    }


# Cell
def create_folders(path:str, label:str) -> None:
    """create the target folder"""
    path = Path(path)
    path.mkdir(parents=True, exist_ok=True)
    path_pos = path / label
    path_pos.mkdir(parents=True, exist_ok=True)
    path_neg = path / ('no_' + label)
    path_neg.mkdir(parents=True, exist_ok=True)

# Cell
def load_fastai_model(path, test_folder:[Path, str]=None):
    """load a fastai model from a given path"""
    path = Path(path)
    folder = path.parent
    file = path.name
    if test_folder is not None:
        il = ImageList.from_folder(test_folder)
        return load_learner(path=folder, file=file, test=il)
    return load_learner(str(folder), str(file))


# Cell
def save_base64_image(path, filename, uri):
    """save base64 encoded image """
    tgt_path = Path(path) / filename
    pil_image = PIL.Image.open(io.BytesIO(b64_uri_to_bytes(uri)))
    pil_image.save(str(tgt_path))

# Cell
def score_stream(stream, model_path):
    learn = load_fastai_model(model_path)
    for example in stream:
        if not example["image"].startswith("data"):
            msg = "Expected base64-encoded data URI, but got: '{}'."
            raise ValueError(msg.format(example["image"][:100]))

        pil_image = PIL.Image.open(io.BytesIO(b64_uri_to_bytes(example["image"])))
        a = np.asarray(pil_image)
        a = np.transpose(a, (1, 0, 2))
        a = np.transpose(a, (2, 1, 0))
        x = torch.from_numpy(a.astype(np.float32, copy=False) )
        x = x.div_(255)
        score = learn.predict(Image(x))[2][0].numpy().item()
        print(f"socre={score}, id={example['text']}")
        yield (score, example)

# Cell
def predict_folder(image_folder:[str, Path], path_model:[str, Path]=Path('data/export.pkl')):
    """predicts a folder of images and saves images in tasks.jsonl"""
    image_folder = Path(image_folder)
    path_model = Path(path_model)
    learn = load_fastai_model(str(path_model), test_folder=str(image_folder))
    preds,y = learn.get_preds(ds_type=DatasetType.Test)
    scores = preds[:,learn.data.classes.index('horse_poo')].numpy()
    paths = learn.data.test_ds.items

    jsonl_list = []
    for score, path in sorted(zip(scores, paths), reverse=True):
            obj = {"image": str(path), "text": path.stem, "score": str(np.round(score, 3))}
            jsonl_list.append(obj)

    print(f"save results to {str(image_folder / 'tasks.jsonl')}")
    write_jsonl(str(image_folder / 'tasks.jsonl'), jsonl_list)


    return learn, preds, y, jsonl_list

# Cell
@call_parse
def predict_all_subfolders(path:Param("path of parent folder", str)='data',
                           skipXmostRecent:Param("skips the nth most recent folders", int)=1,
                           path_model:Param("path to the model to use", str)='data/export.pkl',
                           predict_single_folder:Param("path to single folder", str)=None):
    """predicts all images in subfolders of the given path an creates a tasks.jsonl file"""
    path = Path(path)

    if predict_single_folder is not None:
        predict_folder(Path(predict_single_folder), path_model)
        return

    subfolders = sorted(next(os.walk(str(path)))[1], reverse=True)

    subfolders = [path / folder for folder in subfolders]

    for folder in subfolders[skipXmostRecent:]:
        print(f'predict {folder}')
        predict_folder(folder, path_model)



# Cell
@recipe(
    "fastai_jsonl_recipe",
    dataset=("The dataset to use", "positional", None, str),
    path_image_folder=("folder with tasks.jsonl file", "option", "path_image_folder", str),
    path_model=("folder where we can find the deployed model", "option", "path_model", str),
    predict=("wether to predict if there is already a tasks.jsonl or not", "option", "predict", int)
)
def fastai_jsonl_recipe(dataset, path_image_folder, path_model, predict=0):
    """recipe to predict and laod data in a certain order"""


    def on_load(controller):
        """crates tasks.jsonl file order by predictions"""
        if predict == 1 or os.path.exists(path_image_folder) is False:
            print(f'make predictions for folder {path_image_folder} and model {path_model}')
            predict_folder(image_folder=Path(path_image_folder), path_model=Path(path_model))

    source = Path(path_image_folder)
    stream = JSONL(str(source / 'tasks.jsonl'))
    stream = fetch_images(stream, skip=True)

    return {
        "dataset": dataset,
        "view_id": "image_manual",
        "on_load": on_load,
        "stream": stream,
        "config": {  # Additional config settings, mostly for app UI
            "label": "horse_poo"
        }

    }
